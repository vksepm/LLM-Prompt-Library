# LLMÂ PromptÂ Library

---
## âš¡ Quick peek

* **Live demo** â†’ <https://vksepm.github.io/LLM-Prompt-Library/>  
  Zero-JS until you open the page; the prompt list is rendered client-side from `prompts/INDEX.md`.
  
---

## âœ¨ Prompt catalogue (live)

> ğŸ“– Full list lives in [`prompts/INDEX.md`](prompts/INDEX.md) â€” rebuilt on every commit.

---

## ğŸš€ QuickÂ start

```bash
git clone https://github.com/vksepm/LLM-Prompt-Library.git
cd LLM-Prompt-Library

# helper scripts
pip install -r scripts/requirements.txt

# rebuild catalogue & README counts (CI & preâ€‘commit do this automatically)
python scripts/build_index.py
```
â¸»

The library includes several tools to help you work with prompts:

- **ğŸ” Prompt Validator** - Validates the format and contents of prompt files to ensure they meet our standards.
- **ğŸ”„ Prompt Mixer** - Create new prompts by mixing and matching elements from existing prompts.
- **ğŸ”¢ Token Counter** - Analyze prompt files to count tokens and estimate API costs.
- **ğŸ“Š Prompt Analyzer** - Evaluate the quality of prompts and get suggestions for improvements.
- **ğŸ”„ Prompt Evolution** - Automatically optimize prompts through iterative self-improvement cycles.